{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brainstorming for potential data visualizations and some data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#other \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from https://bakeoff.netlify.app/index.html)\n",
    "baker_results = pd.read_csv('data/baker_results.csv',encoding = \"ISO-8859-1\")\n",
    "challenge_results = pd.read_csv('data/challenge_results.csv',encoding = \"ISO-8859-1\")\n",
    "ratings_seasons = pd.read_csv('data/ratings_seasons.csv',encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from https://medium.com/analytics-vidhya/analyzing-the-great-british-bake-off-part-1-ffcdf3791bf3\n",
    "gbbo_org = pd.read_csv('data/gbbo.csv')\n",
    "gbbo = gbbo_org.iloc[:,:-2]\n",
    "gbbo['Season'] = gbbo['Season'].str[7:].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**average 7 day viewership by series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average 7 day viewership by series\n",
    "viewers_by_season8 = ratings_seasons.groupby('series').mean().reset_index()[['series','viewers_7day']]\n",
    "\n",
    "# add season 9 and 10 manually (https://en.wikipedia.org/wiki/The_Great_British_Bake_Off_(series_9))\n",
    "avg_viewers9 = (9.55 + 9.31 + 8.91 + 8.88 + 8.67 + 8.91 + 9.22 + 9.69 + 9.5 + 10.34)/10\n",
    "avg_viewers10 = (9.62 + 9.38 + 8.94 + 8.96 + 9.26 + 8.70 + 8.98 + 9.19 + 9.34 + 10.05)/10\n",
    "avg_viewers910 = pd.DataFrame({'series':[9,10],'viewers_7day':[avg_viewers9,avg_viewers10]})\n",
    "\n",
    "# put all series together\n",
    "viewers_by_season = pd.concat([viewers_by_season8,avg_viewers910 ],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to json\n",
    "dct = {'data': viewers_by_season.values.tolist()}\n",
    "with open('../data/viewers_by_season.json', 'w') as file:\n",
    "    json.dump(dct,file,indent=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**age breakdown of contestants**\n",
    "- series 1-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to group ages\n",
    "def age_group(age):\n",
    "    if age>=17 and age<30:\n",
    "        return '17 to 30'\n",
    "    if age>=30 and age<45:\n",
    "        return '30 to 45'\n",
    "    if age>=45 and age<60:\n",
    "        return '45 to 59'\n",
    "    else:\n",
    "        return '60+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only bakers\n",
    "gbbo_bakers = gbbo.drop_duplicates(subset=['Season','Baker'])[['Season','Baker','Gender','Age']]\n",
    "\n",
    "# age breakdown\n",
    "ages = gbbo_bakers['Age'].apply(age_group).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "df = pd.DataFrame(ages).reset_index()\n",
    "df.columns = ['name','y']\n",
    "\n",
    "# export to json\n",
    "data = list(df.apply(pd.Series.to_json,axis=1).apply(json.loads))\n",
    "with open('../data/ages.json', 'w') as file:\n",
    "    json.dump(data,file,indent=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gender breakdown**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender breakdown\n",
    "gender = gbbo_bakers['Gender'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "df = pd.DataFrame(gender).reset_index()\n",
    "df.columns = ['name','y']\n",
    "\n",
    "#export to json\n",
    "data = list(df.apply(pd.Series.to_json,axis=1).apply(json.loads))\n",
    "with open('../data/gender.json', 'w') as file:\n",
    "    json.dump(data,file,indent=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**word cloud of the bake titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split bake titles\n",
    "words = pd.Series(challenge_results['signature'].dropna().str.split().sum() + \n",
    "                      challenge_results['showstopper'].dropna().str.split().sum())\n",
    "words = words.apply(lambda x:'Chocolate' if x == \"Chocolate,\" else x)\n",
    "\n",
    "# no common words\n",
    "stopwords = ['and','&','with','a','of','The','the']\n",
    "words = words[~ words.isin(pd.Series(stopwords))]\n",
    "\n",
    "# first 250 words\n",
    "small_words = pd.DataFrame(words.value_counts()).reset_index()[:250]\n",
    "\n",
    "# export json\n",
    "small_words.columns = ['name','weight']\n",
    "small_words = small_words.apply(pd.Series.to_json,axis=1)\n",
    "dct = {}\n",
    "dct['words'] = list(small_words.apply(json.loads))\n",
    "with open('../data/bake_words.json', 'w') as file:\n",
    "    json.dump(dct,file,indent=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare winners handshakes, technicals, star_baker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get winners for first data source\n",
    "winners8 = baker_results[baker_results['series_winner']==1].sort_values('series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get s1-8 winners for second data source\n",
    "w = gbbo[(gbbo['Winner']==1) | ((gbbo['Baker']=='David') & (gbbo['Season']==10))]\n",
    "handshakes = w.groupby(\n",
    "    'Baker').sum()[['Signature Handshake','Showstopper Handshake']]\n",
    "winners_list = list(winners8['baker']) + ['Rahul','David']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rahul = gbbo[(gbbo['Baker']=='Rahul') & (gbbo['Season']==9)]\n",
    "david = gbbo[(gbbo['Baker']=='David') & (gbbo['Season']==10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get num of start bakers, technical wins, and handshakes\n",
    "dct = {}\n",
    "dct['bakers'] = winners_list\n",
    "dct['star_baker'] = list(winners8['star_baker']) + [int(rahul['Star Baker'].sum()-1), # hard code to fix data inconsistencies\n",
    "                                                    int(david['Star Baker'].sum()+1)]\n",
    "dct['technical'] = list(winners8['technical_winner']) + [int((rahul['Technical Rank']==1).sum()),\n",
    "                                                         int((david['Technical Rank']==1).sum())]\n",
    "dct['handshake'] = list(handshakes['Signature Handshake'] + handshakes['Showstopper Handshake'])\n",
    "\n",
    "# to json\n",
    "with open('../data/winners_stats.json', 'w') as file:\n",
    "    json.dump(dct,file,indent=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bubble chart of winner based on instagram + twitter followers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collected manually as of 6/6/20\n",
    "insta = pd.DataFrame({'baker': ['Edd','Joanne','John','Frances','Nancy','Nadiya','Candice','Sophie','Rahul','David'],\n",
    "                      'age': list(w.drop_duplicates('Baker')['Age']),\n",
    "                      'occupation': list(winners8['occupation']) +['Engineering Researcher','Health Advisor'],\n",
    "                      'hometown': list(winners8['hometown']) + ['Howrah, India','Whitby'],\n",
    "                     'followers': [288+40.9, 26.3, 79.8+89.1, 49.1+74.6, 104+38.1, 520+236.8, 239+93.9, 31.5+21.7,\n",
    "                                  188+1, 122+22],\n",
    "                     'series': list(np.arange(1,11)),\n",
    "                     'image_path': ['images/bakers/edd.jpg','images/bakers/joanne.jpg','images/bakers/john.jpg',\n",
    "                                    'images/bakers/frances.jpg','images/bakers/nancy.jpg','images/bakers/nadiya.jpg',\n",
    "                                    'images/bakers/candice.jpg','images/bakers/sophie.jpg','images/bakers/rahul.jpg',\n",
    "                                   'images/bakers/david.jpg'],\n",
    "                     'wiki': ['https://en.wikipedia.org/wiki/Edd_Kimber','https://en.wikipedia.org/wiki/Joanne_Wheatley',\n",
    "                             'https://en.wikipedia.org/wiki/John_Whaite', 'https://en.wikipedia.org/wiki/Frances_Quinn',\n",
    "                             'https://en.wikipedia.org/wiki/Nancy_Birtwhistle', 'https://en.wikipedia.org/wiki/Nadiya_Hussain',\n",
    "                             'https://en.wikipedia.org/wiki/Candice_Brown','https://en.wikipedia.org/wiki/Sophie_Faldo',\n",
    "                             'https://en.wikipedia.org/wiki/Rahul_Mandal','https://en.wikipedia.org/wiki/David_Atherton_(baker)']\n",
    "                     })\n",
    "insta.to_csv('../data/insta.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dashboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most star bakers\n",
    "gbbo[gbbo['Season'].isin([9,10])].groupby('Baker').sum()['Star Baker'].max()\n",
    "baker_results.iloc[baker_results['star_baker'].idxmax()][['series','baker','star_baker']] \n",
    "\n",
    "# best technical baker\n",
    "gbbo[(gbbo['Season'].isin([9,10])) & (gbbo['Technical Rank']==1)].groupby('Baker')['Technical Rank'].count().max()\n",
    "baker_results.iloc[baker_results['technical_winner'].idxmax()][['series','baker','technical_winner']] \n",
    "\n",
    "# 34 handshakes given\n",
    "(gbbo['Signature Handshake']+gbbo['Showstopper Handshake']).sum() \n",
    "\n",
    "#handshakes by season\n",
    "handshakes_by_season = gbbo.groupby('Season').sum()[['Showstopper Handshake','Signature Handshake']].sum(axis=1)\n",
    "\n",
    "# export to json\n",
    "dct = {'data': handshakes_by_season.values.tolist()}\n",
    "with open('../data/handshakes_by_season.json', 'w') as file:\n",
    "    json.dump(dct,file,indent=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
